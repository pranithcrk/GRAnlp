{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Manoj Patil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Manoj\n",
      "[nltk_data]     Patil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "420/420 [==============================] - 2s 3ms/step - loss: 0.4219 - accuracy: 0.8548 - val_loss: 0.3464 - val_accuracy: 0.8619\n",
      "Epoch 2/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.2650 - accuracy: 0.8762 - val_loss: 0.2386 - val_accuracy: 0.9000\n",
      "Epoch 3/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.1408 - accuracy: 0.9512 - val_loss: 0.2259 - val_accuracy: 0.9048\n",
      "Epoch 4/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0648 - accuracy: 0.9869 - val_loss: 0.2384 - val_accuracy: 0.9000\n",
      "Epoch 5/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9952 - val_loss: 0.2661 - val_accuracy: 0.9095\n",
      "Epoch 6/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0122 - accuracy: 0.9988 - val_loss: 0.2986 - val_accuracy: 0.9143\n",
      "Epoch 7/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.3134 - val_accuracy: 0.9095\n",
      "Epoch 8/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3284 - val_accuracy: 0.9095\n",
      "Epoch 9/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.9095\n",
      "Epoch 10/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.9095\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.9095\n",
      "Test Loss: 0.3635207712650299, Test Accuracy: 0.9095237851142883\n",
      "Model saved to trained_model_A1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manoj Patil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import pos_tag \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import joblib\n",
    "# Download NLTK resources\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def load_data(file_path):\n",
    "    # Load data from CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "def split_data(feature,labels):\n",
    "    # Split the data into training and testing sets\n",
    "    sentences = feature\n",
    "    label = labels\n",
    "    cleaned_text = preprocess_text(sentences)\n",
    "    \n",
    "    clean_converted = convert_input(cleaned_text)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(clean_converted, label, test_size=0.2, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test, tokenizer\n",
    "\n",
    "def preprocess_text(sentences):\n",
    "    # Perform necessary preprocessing steps like tokenization, stopword removal, stemming, lemmatization, etc.\n",
    "    cleaned_text = []\n",
    "    for text in sentences:\n",
    "        cleaned_text.append(preprocess_single_text(text))\n",
    "    return cleaned_text\n",
    "\n",
    "def preprocess_single_text(text):\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove all tokens which are non-alphabetic\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "    # Lowercase all words\n",
    "    words = [word.lower() for word in words]\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Lemmatize all words into a new list\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # Return a list of words\n",
    "    return ' '.join(words)\n",
    "\n",
    "def build_model(tokenizer):\n",
    "    # Build the model\n",
    "    embedding_dim = 16\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=20))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model(model, x_train, y_train, x_test, y_test):\n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, epochs=10, batch_size=2, validation_data=(x_test, y_test))\n",
    "\n",
    "def evaluate_model(model, x_test, y_test):\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "def predict_and_print_labels(model, some_input, tokenizer):\n",
    "    # Predict labels for test sentences and print the results\n",
    "    converted_input = convert_input(some_input)\n",
    "    predictions = model.predict(converted_input)\n",
    "\n",
    "    for i in range(len(test_sentences)):\n",
    "        label = \"Positive\" if predictions[i] > 0.5 else \"Negative\"\n",
    "        print(f\"Text: {test_sentences[i]}, Predicted label: {label}\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "    \n",
    "def convert_input(test_sentences):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(test_sentences)\n",
    "    sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=20, padding='post', truncating='post')\n",
    "\n",
    "    return padded_sequences\n",
    "\n",
    "\n",
    "def save_model(model, filename):\n",
    "    # Save the model to a file\n",
    "    model.save(filename)\n",
    "    print(f\"Model saved to {filename}\")\n",
    "\n",
    "def load_saved_model(filename):\n",
    "    # Load a saved model from a file\n",
    "    loaded_model = tf.keras.models.load_model(filename)\n",
    "    print(f\"Model loaded from {filename}\")\n",
    "    return loaded_model\n",
    "\n",
    "def create_binary_model(file_path,label_col):\n",
    "    df = load_data(file_path)\n",
    "    features = df['Obs']\n",
    "    labels = df[label_col]\n",
    "    x_train, x_test, y_train, y_test,tokenizer = split_data(features,labels)\n",
    "    model = build_model(tokenizer)\n",
    "    train_model(model, x_train, y_train, x_test, y_test)\n",
    "    evaluate_model(model, x_test, y_test)\n",
    "    save_model(model, f'trained_model_{label_col}.h5')\n",
    "# loaded_model = load_saved_model('trained_model1.h5')\n",
    "\n",
    "def create_testers(df,label_colummn,x,y):\n",
    "    test_sentences = df['Obs'][x:y].tolist()\n",
    "    test_labels = df[label_colummn][x:y]\n",
    "    all_labels = df[['A1','A2','A3','B1','B2','B3','B4']][x:y]\n",
    "\n",
    "    return test_sentences,test_labels,all_labels\n",
    "\n",
    "\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    precision, recall, f1_score, support = precision_recall_fscore_support(y_true, y_pred)\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def save_results(predictions, precision, recall, f1_score, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        joblib.dump({\"predictions\": predictions, \"precision\": precision, \"recall\": recall, \"f1_score\": f1_score}, f)\n",
    "\n",
    "def predict_ensemble(models, X):\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "   \n",
    "        predictions.append(model.predict(X))\n",
    "\n",
    "  # Take the average of the predictions from each model.\n",
    "    \n",
    "\n",
    "    return predictions\n",
    "\n",
    "def convert_predictions_to_binary(predictions):\n",
    "    # Convert predictions to binary\n",
    "    binary_predictions = []\n",
    "    for prediction in predictions:\n",
    "        binary_prediction = []\n",
    "        for value in prediction:\n",
    "            if value > 0.5:\n",
    "                binary_prediction.append(1)\n",
    "            else:\n",
    "                binary_prediction.append(0)\n",
    "        binary_predictions.append(binary_prediction)\n",
    "    return binary_predictions\n",
    "\n",
    "    \n",
    "create_binary_model('Problem_Dataset.csv','A1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "420/420 [==============================] - 2s 3ms/step - loss: 0.4180 - accuracy: 0.8512 - val_loss: 0.2968 - val_accuracy: 0.8762\n",
      "Epoch 2/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.2019 - accuracy: 0.9095 - val_loss: 0.1660 - val_accuracy: 0.9619\n",
      "Epoch 3/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.1005 - accuracy: 0.9643 - val_loss: 0.1605 - val_accuracy: 0.9571\n",
      "Epoch 4/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0434 - accuracy: 0.9917 - val_loss: 0.1708 - val_accuracy: 0.9476\n",
      "Epoch 5/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0203 - accuracy: 0.9964 - val_loss: 0.1848 - val_accuracy: 0.9333\n",
      "Epoch 6/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9429\n",
      "Epoch 7/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9286\n",
      "Epoch 8/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9286\n",
      "Epoch 9/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9286\n",
      "Epoch 10/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9238\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2593 - accuracy: 0.9238\n",
      "Test Loss: 0.2593272030353546, Test Accuracy: 0.9238095283508301\n",
      "Model saved to trained_model_A2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manoj Patil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "420/420 [==============================] - 2s 3ms/step - loss: 0.4253 - accuracy: 0.8536 - val_loss: 0.3700 - val_accuracy: 0.8524\n",
      "Epoch 2/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.2399 - accuracy: 0.8917 - val_loss: 0.2230 - val_accuracy: 0.9238\n",
      "Epoch 3/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.1203 - accuracy: 0.9536 - val_loss: 0.2147 - val_accuracy: 0.9333\n",
      "Epoch 4/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0701 - accuracy: 0.9774 - val_loss: 0.2166 - val_accuracy: 0.9286\n",
      "Epoch 5/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0379 - accuracy: 0.9917 - val_loss: 0.2244 - val_accuracy: 0.9429\n",
      "Epoch 6/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9976 - val_loss: 0.2405 - val_accuracy: 0.9333\n",
      "Epoch 7/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0121 - accuracy: 0.9988 - val_loss: 0.2578 - val_accuracy: 0.9333\n",
      "Epoch 8/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9429\n",
      "Epoch 9/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9429\n",
      "Epoch 10/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.9333\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.9333\n",
      "Test Loss: 0.3005546033382416, Test Accuracy: 0.9333333373069763\n",
      "Model saved to trained_model_A3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manoj Patil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.3565 - accuracy: 0.8631 - val_loss: 0.2303 - val_accuracy: 0.8333\n",
      "Epoch 2/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.1138 - accuracy: 0.9583 - val_loss: 0.1436 - val_accuracy: 0.9524\n",
      "Epoch 3/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0271 - accuracy: 0.9952 - val_loss: 0.1428 - val_accuracy: 0.9476\n",
      "Epoch 4/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9619\n",
      "Epoch 5/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9524\n",
      "Epoch 6/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9619\n",
      "Epoch 7/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 9.8317e-04 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9619\n",
      "Epoch 8/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 6.3430e-04 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 0.9524\n",
      "Epoch 9/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 4.2761e-04 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9524\n",
      "Epoch 10/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 2.9790e-04 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9524\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.9524\n",
      "Test Loss: 0.17752084136009216, Test Accuracy: 0.9523809552192688\n",
      "Model saved to trained_model_B1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manoj Patil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "420/420 [==============================] - 2s 3ms/step - loss: 0.3469 - accuracy: 0.8595 - val_loss: 0.1717 - val_accuracy: 0.9524\n",
      "Epoch 2/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0710 - accuracy: 0.9869 - val_loss: 0.0946 - val_accuracy: 0.9571\n",
      "Epoch 3/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0184 - accuracy: 0.9976 - val_loss: 0.0815 - val_accuracy: 0.9667\n",
      "Epoch 4/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0090 - accuracy: 0.9988 - val_loss: 0.0938 - val_accuracy: 0.9667\n",
      "Epoch 5/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0955 - val_accuracy: 0.9667\n",
      "Epoch 6/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9619\n",
      "Epoch 7/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 7.7947e-04 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9667\n",
      "Epoch 8/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 5.0566e-04 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9667\n",
      "Epoch 9/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 3.4175e-04 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9667\n",
      "Epoch 10/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 2.4349e-04 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9667\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9667\n",
      "Test Loss: 0.09930545091629028, Test Accuracy: 0.9666666388511658\n",
      "Model saved to trained_model_B2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manoj Patil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "420/420 [==============================] - 2s 3ms/step - loss: 0.3888 - accuracy: 0.8643 - val_loss: 0.3301 - val_accuracy: 0.8286\n",
      "Epoch 2/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.8881 - val_loss: 0.1608 - val_accuracy: 0.9381\n",
      "Epoch 3/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0443 - accuracy: 0.9917 - val_loss: 0.1127 - val_accuracy: 0.9476\n",
      "Epoch 4/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9476\n",
      "Epoch 5/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9524\n",
      "Epoch 6/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9524\n",
      "Epoch 7/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 8.2637e-04 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9524\n",
      "Epoch 8/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 5.1977e-04 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9524\n",
      "Epoch 9/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 3.4362e-04 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9524\n",
      "Epoch 10/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 2.3711e-04 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9524\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9524\n",
      "Test Loss: 0.12668044865131378, Test Accuracy: 0.9523809552192688\n",
      "Model saved to trained_model_B3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manoj Patil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "420/420 [==============================] - 2s 2ms/step - loss: 0.4184 - accuracy: 0.8500 - val_loss: 0.2864 - val_accuracy: 0.8714\n",
      "Epoch 2/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.1562 - accuracy: 0.9179 - val_loss: 0.0868 - val_accuracy: 0.9667\n",
      "Epoch 3/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0294 - accuracy: 0.9964 - val_loss: 0.0667 - val_accuracy: 0.9762\n",
      "Epoch 4/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0085 - accuracy: 0.9988 - val_loss: 0.0566 - val_accuracy: 0.9762\n",
      "Epoch 5/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0614 - val_accuracy: 0.9762\n",
      "Epoch 6/10\n",
      "420/420 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 0.9714\n",
      "Epoch 7/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 9.9576e-04 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9762\n",
      "Epoch 8/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 6.1699e-04 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9714\n",
      "Epoch 9/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 4.0216e-04 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9714\n",
      "Epoch 10/10\n",
      "420/420 [==============================] - 1s 3ms/step - loss: 2.7875e-04 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9714\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9714\n",
      "Test Loss: 0.06525935977697372, Test Accuracy: 0.9714285731315613\n",
      "Model saved to trained_model_B4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manoj Patil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "create_binary_model('Problem_Dataset.csv','A2')\n",
    "create_binary_model('Problem_Dataset.csv','A3')\n",
    "create_binary_model('Problem_Dataset.csv','B1')\n",
    "create_binary_model('Problem_Dataset.csv','B2')\n",
    "create_binary_model('Problem_Dataset.csv','B3')\n",
    "create_binary_model('Problem_Dataset.csv','B4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from trained_model_A1.h5\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Text: Observed child fixated on a particular texture, rubbing a piece of sandpaper continuously throughout the appointment., Predicted label: Negative\n",
      "Text: Patient's focus centers on vacuum cleaners, studying different models and their components., Predicted label: Negative\n",
      "Text: Displays a strong interest in smelling various objects, often lingering on scents for prolonged periods., Predicted label: Negative\n",
      "Text: Patient's attachment to a specific book is evident, quoting passages frequently., Predicted label: Negative\n",
      "Text: Limited awareness of personal boundaries, invades others' personal space., Predicted label: Positive\n",
      "Text: Repeatedly opens and closes doors, seemingly fascinated by the motion of hinges., Predicted label: Negative\n",
      "Text: Engages in repetitive smelling and touching of objects in her environment., Predicted label: Negative\n",
      "Text: Has difficulties in understanding social cues and often misinterprets facial expressions and body language., Predicted label: Negative\n",
      "Text: Demonstrates a need to perform certain actions repetitively, such as tapping a surface a specific number of times before proceeding with a task., Predicted label: Negative\n",
      "Text: Engages in repetitive touching of textured surfaces, displaying heightened sensory awareness., Predicted label: Negative\n",
      "[[2.2158523e-01]\n",
      " [1.7671817e-04]\n",
      " [9.1707278e-03]\n",
      " [4.0647112e-07]\n",
      " [7.8412414e-01]\n",
      " [7.2831655e-04]\n",
      " [2.0612252e-01]\n",
      " [3.2588476e-04]\n",
      " [3.2126219e-03]\n",
      " [1.7065406e-02]]\n",
      "[[0], [0], [0], [0], [1], [0], [0], [0], [0], [0]]\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "Name: A1, dtype: int64\n",
      "   A1  A2  A3  B1  B2  B3  B4\n",
      "0   0   0   0   0   0   1   0\n",
      "1   0   0   0   0   0   1   0\n",
      "2   0   0   0   0   0   0   1\n",
      "3   0   0   0   0   0   1   0\n",
      "4   0   0   1   0   0   0   0\n",
      "5   0   0   0   1   0   0   0\n",
      "6   0   0   0   0   0   0   1\n",
      "7   0   0   1   0   0   0   0\n",
      "8   0   0   0   0   1   0   0\n",
      "9   0   0   0   1   0   0   0\n",
      "Precision: [1. 0.], Recall: [0.9 0. ], F1-score: [0.94736842 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manoj Patil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Example usage for prediction\n",
    "test_sentences,test_labels,all_labelss = create_testers(df,'A1',0,10)\n",
    "\n",
    "loaded_model = load_saved_model('trained_model_A1.h5')\n",
    "predeictionsss = predict_and_print_labels(loaded_model, test_sentences, tokenizer)\n",
    "print(predeictionsss)\n",
    "binary_predeictionsss = convert_predictions_to_binary(predeictionsss)\n",
    "\n",
    "print(binary_predeictionsss)\n",
    "print(test_labels)\n",
    "print(all_labelss)\n",
    "precision, recall, f1_score = calculate_metrics(test_labels, binary_predeictionsss)\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1-score: {f1_score}\")\n",
    "\n",
    "save_results(binary_predeictionsss, precision, recall, f1_score, \"results.pkl\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A1  A2  A3  B1  B2  B3  B4\n",
      "1   0   0   0   0   0   1   0\n",
      "[[ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[array([[0.32294694]], dtype=float32), array([[2.513604e-05]], dtype=float32), array([[0.5854795]], dtype=float32), array([[0.00030022]], dtype=float32), array([[1.231672e-05]], dtype=float32), array([[0.09366304]], dtype=float32), array([[0.00017045]], dtype=float32)]\n",
      "[[0], [0], [1], [0], [0], [0], [0]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 7]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Manoj Patil\\Desktop\\nlptask\\test.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Manoj%20Patil/Desktop/nlptask/test.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(ensemble_predictions)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Manoj%20Patil/Desktop/nlptask/test.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(binary_ensemble_predictions)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Manoj%20Patil/Desktop/nlptask/test.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m ensemble_precision, ensemble_recall, ensemble_f1_score \u001b[39m=\u001b[39m calculate_metrics(test3, ensemble_predictions)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manoj%20Patil/Desktop/nlptask/test.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPrecision: \u001b[39m\u001b[39m{\u001b[39;00mensemble_precision\u001b[39m}\u001b[39;00m\u001b[39m, Recall: \u001b[39m\u001b[39m{\u001b[39;00mensemble_recall\u001b[39m}\u001b[39;00m\u001b[39m, F1-score: \u001b[39m\u001b[39m{\u001b[39;00mensemble_f1_score\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Manoj Patil\\Desktop\\nlptask\\test.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Manoj%20Patil/Desktop/nlptask/test.ipynb#W2sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_metrics\u001b[39m(y_true, y_pred):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Manoj%20Patil/Desktop/nlptask/test.ipynb#W2sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m     precision, recall, f1_score, support \u001b[39m=\u001b[39m precision_recall_fscore_support(y_true, y_pred)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Manoj%20Patil/Desktop/nlptask/test.ipynb#W2sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m precision, recall, f1_score\n",
      "File \u001b[1;32mc:\\Users\\Manoj Patil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Manoj Patil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1721\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1563\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1564\u001b[0m \n\u001b[0;32m   1565\u001b[0m \u001b[39mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[39m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m zero_division_value \u001b[39m=\u001b[39m _check_zero_division(zero_division)\n\u001b[1;32m-> 1721\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1723\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1724\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Manoj Patil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1499\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1497\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1499\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   1500\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\Manoj Patil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m     85\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Manoj Patil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 7]"
     ]
    }
   ],
   "source": [
    "\n",
    "test1,test2,test3 = create_testers(df,'A1',1,2)\n",
    "converted_test1 = convert_input(test1)\n",
    "print(test3)\n",
    "print(converted_test1)\n",
    "ensemble_predictions = predict_ensemble(models, converted_test1)\n",
    "binary_ensemble_predictions = convert_predictions_to_binary(ensemble_predictions)\n",
    "\n",
    "print(ensemble_predictions)\n",
    "print(binary_ensemble_predictions)\n",
    "\n",
    "ensemble_precision, ensemble_recall, ensemble_f1_score = calculate_metrics(test3, ensemble_predictions)\n",
    "print(f\"Precision: {ensemble_precision}, Recall: {ensemble_recall}, F1-score: {ensemble_f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1,test2,test3 = create_testers(df,'A3',0,1)\n",
    "converted_test1 = convert_input(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  3  4  5  1  6  7  8  1  9 10 11 12 13 14 15  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(converted_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[array([[0.07126191]], dtype=float32), array([[0.00241495]], dtype=float32), array([[0.9489908]], dtype=float32), array([[0.00231021]], dtype=float32), array([[3.33789e-05]], dtype=float32), array([[0.39199013]], dtype=float32), array([[0.04412718]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "ensemble_predictions = predict_ensemble(models, converted_test1)\n",
    "\n",
    "print(ensemble_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
